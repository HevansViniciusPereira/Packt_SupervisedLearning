{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking with Standalone and Ensemble Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Import the relevant libraries </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read the data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston_house_prices.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Preprocess the dataset to remove null values and one-hot encoded categorical variables to prepare the data for modeling </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'INDUS',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'AGE',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT',\n",
       " 'PRICE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many columns have less than 10 % null data\n",
    "perc_missing = data.isnull().mean() * 100\n",
    "cols = perc_missing[perc_missing < 10].index.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Divide the dataset into train and validation DataFrames </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data_final, test_size=0.2, random_state=11)\n",
    "\n",
    "x_train = train.drop(columns=['PRICE'])\n",
    "y_train = train['PRICE'].values\n",
    "\n",
    "x_val = val.drop(columns=['PRICE'])\n",
    "y_val = val['PRICE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Initialize dictionaries in which to store the train and validation MAE values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae, val_mae = {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train a DecisionTreeRegressor model (dt) with the following hyperparameters and save the scores: </b>\n",
    "    \n",
    "dt_params = { <br>\n",
    "    'criterion': 'mae',<br>\n",
    "    'min_samples_leaf': 15,<br>\n",
    "    'random_state': 11<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    'criterion': 'mae',\n",
    "    'min_samples_leaf': 15,\n",
    "    'random_state': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mae', min_samples_leaf=15, random_state=11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the model\n",
    "dt = DecisionTreeRegressor(**dt_params)\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "dt_preds_train = dt.predict(x_train)\n",
    "dt_preds_val = dt.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean absolute error\n",
    "train_mae['dt'] = mean_absolute_error(y_train, dt_preds_train)\n",
    "val_mae['dt'] = mean_absolute_error(y_val, dt_preds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train a KNeighborsRegressor model (knn) with the following hyperparameters and save the scores: </b>\n",
    "    \n",
    "knn_params = {'n_neighbors': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "knn_params = {'n_neighbors': 5}\n",
    "knn = KNeighborsRegressor(**knn_params)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "knn_preds_train = knn.predict(x_train)\n",
    "knn_preds_val = knn.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean absolute error\n",
    "train_mae['knn'] = mean_absolute_error(y_train, knn_preds_train)\n",
    "val_mae['knn'] = mean_absolute_error(y_val, knn_preds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train a RandomForestRegressor model (rf) with the following hyperparameters and save the scores </b>\n",
    "\n",
    "rf_params = { <br>\n",
    "    'n_estimators': 20,<br>\n",
    "    'criterion': 'mae',<br>\n",
    "    'max_features': 'sqrt',<br>\n",
    "    'min_samples_leaf': 10,<br>\n",
    "    'random_state': 11,<br>\n",
    "    'n_jobs': -1<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters\n",
    "rf_params = {\n",
    "    'n_estimators': 20,\n",
    "    'criterion': 'mae',\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 10,\n",
    "    'random_state': 11,\n",
    "    'n_jobs': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='mae', max_features='sqrt', min_samples_leaf=10,\n",
       "                      n_estimators=20, n_jobs=-1, random_state=11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "rf = RandomForestRegressor(**rf_params)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "rf_preds_train = rf.predict(x_train)\n",
    "rf_preds_val = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean absolute error\n",
    "train_mae['rf'] = mean_absolute_error(y_train, rf_preds_train)\n",
    "val_mae['rf'] = mean_absolute_error(y_val, rf_preds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train a GradientBoostingRegressor model (gbr) with the following hyperparameters and save the scores </b>\n",
    "\n",
    "gbr_params = { <br>\n",
    "    'n_estimators': 20,<br>\n",
    "    'criterion': 'mae',<br>\n",
    "    'max_features': 'sqrt',<br>\n",
    "    'min_samples_leaf': 10,<br>\n",
    "    'random_state': 11<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters\n",
    "gbr_params = {\n",
    "    'n_estimators': 20,\n",
    "    'criterion': 'mae',\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 10,\n",
    "    'random_state': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(criterion='mae', max_features='sqrt',\n",
       "                          min_samples_leaf=10, n_estimators=20,\n",
       "                          random_state=11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "gbr = GradientBoostingRegressor(**gbr_params)\n",
    "gbr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "gbr_preds_train = gbr.predict(x_train)\n",
    "gbr_preds_val = gbr.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean absolute error\n",
    "train_mae['gbr'] = mean_absolute_error(y_train, gbr_preds_train)\n",
    "val_mae['gbr'] = mean_absolute_error(y_val, gbr_preds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Prepare the training and validation datasets, with the four meta estimators having the same hyperparameters that were used in the previous steps </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# preparing the training set\n",
    "num_base_predictors = len(train_mae)\n",
    "\n",
    "x_train_metapreds = np.zeros((x_train.shape[0], x_train.shape[1]+num_base_predictors))\n",
    "x_train_metapreds[:, :-num_base_predictors] = x_train\n",
    "x_train_metapreds[:, -num_base_predictors:] = -1\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_indices, val_indices in kf.split(x_train):\n",
    "    kfold_x_train, kfold_x_val = x_train.iloc[train_indices], x_train.iloc[val_indices]\n",
    "    kfold_y_train, kfold_y_val = y_train[train_indices], y_train[val_indices]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    dt = DecisionTreeRegressor(**dt_params)\n",
    "    dt.fit(kfold_x_train, kfold_y_train)\n",
    "    predictions.append(dt.predict(kfold_x_val))\n",
    "    \n",
    "    knn = KNeighborsRegressor(**knn_params)\n",
    "    knn.fit(kfold_x_train, kfold_y_train)\n",
    "    predictions.append(knn.predict(kfold_x_val))\n",
    "    \n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    rf.fit(kfold_x_train, kfold_y_train)\n",
    "    predictions.append(rf.predict(kfold_x_val))\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(**gbr_params)\n",
    "    gbr.fit(kfold_x_train, kfold_y_train)\n",
    "    predictions.append(gbr.predict(kfold_x_val))\n",
    "    \n",
    "    for i, preds in enumerate(predictions):\n",
    "        x_train_metapreds[val_indices, -(i+1)] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# preparing the validation set\n",
    "x_val_metapreds = np.zeros((x_val.shape[0], x_val.shape[1]+num_base_predictors))\n",
    "x_val_metapreds[:, :-num_base_predictors] = x_val\n",
    "x_val_metapreds[:, -num_base_predictors:] = -1\n",
    "predictions = []\n",
    "    \n",
    "dt = DecisionTreeRegressor(**dt_params)\n",
    "dt.fit(x_train, y_train)\n",
    "predictions.append(dt.predict(x_val))\n",
    "\n",
    "knn = KNeighborsRegressor(**knn_params)\n",
    "knn.fit(x_train, y_train)\n",
    "predictions.append(knn.predict(x_val))\n",
    "\n",
    "rf = RandomForestRegressor(**rf_params)\n",
    "rf.fit(x_train, y_train)\n",
    "predictions.append(rf.predict(x_val))\n",
    "\n",
    "gbr = GradientBoostingRegressor(**gbr_params)\n",
    "gbr.fit(x_train, y_train)\n",
    "predictions.append(gbr.predict(x_val))\n",
    "for i, preds in enumerate(predictions):\n",
    "    x_val_metapreds[:, -(i+1)] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train a LinearRegression model (lr) as the stacked model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(x_train_metapreds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "lr_preds_train = lr.predict(x_train_metapreds)\n",
    "lr_preds_val = lr.predict(x_val_metapreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean absolute error\n",
    "train_mae['lr'] = mean_absolute_error(y_true=y_train, y_pred=lr_preds_train)\n",
    "val_mae['lr'] = mean_absolute_error(y_true=y_val, y_pred=lr_preds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Visualize the train and validation errors for each individual model and the stacked model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>2.384406</td>\n",
       "      <td>3.282353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>3.455545</td>\n",
       "      <td>3.978039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>2.316120</td>\n",
       "      <td>3.029828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbr</th>\n",
       "      <td>2.452970</td>\n",
       "      <td>3.054477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>2.248086</td>\n",
       "      <td>2.852430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "dt   2.384406  3.282353\n",
       "knn  3.455545  3.978039\n",
       "rf   2.316120  3.029828\n",
       "gbr  2.452970  3.054477\n",
       "lr   2.248086  2.852430"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_scores = pd.concat([pd.Series(train_mae, name='train'), \n",
    "                        pd.Series(val_mae, name='val')], \n",
    "                       axis=1)\n",
    "mae_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae_scores.plot(kind='bar', figsize=(10,7))\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
